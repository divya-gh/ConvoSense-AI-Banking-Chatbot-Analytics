ğŸ§  Linguistic Error Types:
In conversational AI, failures usually fall into three linguistic layers:

Error Types:	                                      Question it answers
Syntax Error :                                 How is the sentence structured?
Semantics Error :	                           What does the sentence mean?
Pragmatics Error :	                           What does the user actually want in context?

### 1ï¸âƒ£ Syntax Errors (Structure Problems)
What This Looks Like:
Syntax errors occur when the sentence structure confuses the model.

#### Examples:
- Long sentences with multiple clauses
- Multiple verbs joined by conjunctions
- Unusual word order

EX: â€œI was charged twice and want to know if I can reverse the paymentâ€

### Analysis : 
- Tokenization showed long token sequences
- POS tagging showed multiple VERBs and conjunctions

## Business Impact: 
Syntactic Error Analysis:
Syntactic failures were observed in utterances containing multiple clauses, conjunctions, and verbs. These structures often represent compound user actions, which exceed the modelâ€™s single-intent classification design, leading to incorrect intent prediction.

### 2ï¸âƒ£ Semantic Errors (Meaning Ambiguity-Multiple meaning)
#### What This Looks Like:
Semantic errors happen when words mean multiple things in banking contexts.

#### Examples:
- â€œchargeâ€ â†’ fee, credit card charge, fraud
- â€œtransferâ€ â†’ internal, external, scheduled
- â€œpaymentâ€ â†’ bill, credit card, loan
- â€œWhy is this charge still pending?â€

### Analysis:
- Confusion matrix shows overlap between transaction-related intents
- Entity extraction is shallow or missing

## Business Imapct:
Semantic Error Analysis:
Semantic ambiguity in domain-specific terms such as "charge", "payment", and "transfer" contributed significantly to misclassification. The absence of fine-grained entity resolution limits the modelâ€™s ability to distinguish between closely related banking intents.

### 3ï¸âƒ£ PragmaticErrors > Failures (Context & Expectation Mismatch)

#### Pragmatic failures occur when:
- The model predicts the correct intent
- BUT responds in a way that does not satisfy the userâ€™s real goal

#### Example:
- User: â€œWhy was my card declined at the gas station?â€
- System: â€œHereâ€™s how to check your balance.â€

### Aalysis: 
âœ” Intent classified correctly
âŒ User goal unmet

### Our project Analyis: 
-Escalation despite correct intent
-High confidence predictions with poor resolution
-Manual review of escalated cases

## Buisness Impact:
Pragmatic Failure Analysis:
Pragmatic failures were identified in cases where the predicted intent matched the userâ€™s query, yet the system response failed to address the userâ€™s underlying goal. This mismatch often resulted in escalation, indicating gaps in contextual understanding and response design rather than intent classification alone.

##  Final Summary:
Linguistic Failure Taxonomy:
The analysis reveals three primary categories of conversational AI failure:

â€¢ Syntactic failures caused by complex sentence structures and multi-action requests  
â€¢ Semantic failures driven by ambiguous domain-specific terminology  
â€¢ Pragmatic failures where system responses do not align with user expectations despite correct intent classification  

Addressing these issues requires a combination of improved intent decomposition, enhanced entity modeling, and context-aware response strategies.
